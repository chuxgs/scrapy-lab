# Lab session 6: Using the Elastic Stack to study scraped data from a web page

### Task 6.1: Extract selected information from a newspaper webpage

**Q61**: We experienced some complications with this exercise since the given code did not work. However, we managed to create 
a working script to extract some data. Specifically, our nytimes.py script retrieves the urls, the titles, and 
the authors of the articles.

One of us had never before scraped a website and this exercise was practical to start understanding how scrapy works and 
can be used. 


### Task 6.2: Obtain a subset of the movie industry to do some research

**Q62**: As the Imdb webpage follows a rather well organized html structure, the first step of the exercise which consisted
in extracting the actors_names of a movie, their ids, and roles, was rather simple.

The next step, which included visiting the authors pages to scrap some of their data such as the height was a bit more complicated.
As mentioned, one of us had never before scraped a website and was also unfamiliar with html code. There was some difficulty
in understanding how to extract the data given the html structure. 

Finally, we extended our spider to scrape other movies found in the actors pages. This posed a lot of problems.
We needed quite a lot of time to figure out how to order the functions so that the yield worked properly. 
The recursivity of the program, needed to scrape the data from many movies, made the code much more complex.

We let it run for 5 minutes approximately to check if it was working properly before passing to the next step.

Most of our time was invested in making this code work properly. The generated script is named staticsearch_imdb.py which can be found in the Lab7 folder.

### Task 6.3: Study the obtained data using the Elastic Stack

**Q63**: Understanding how to create an Elasticsearch index through a python script was a challenge. 
As mentioned in the introductory tutorials we created a deployment and everything seemed to work fine. 
However, when we tried to connect to the endpoint, the connection always failed because we were not properly authenticated. 
The tutorials never mention that should add authentication in your script, we thought the API key was enough. 
We tried a lot of things until we found that the user and the password we needed were the ones generated by elastic right after 
the deployment was performed. 

This showed us the importance of having good documentation at hand.

The following image shows the generated dashboard. 
<img width="1467" alt="image" src="https://github.com/chuxgs/scrapy-lab/assets/128915750/63a8b301-21b0-4734-ad4a-ac2f7542f8fd">

We noted that all actors appear only once in the scraped data. We could find a reason why this might be happening. 
Our code only avoids scraping the same movie twice, but it does not apply any filtering to the actors. Considering that all movies are
scraped through the actors pages, we would expect at least some actors ids to appear more than once in the collected data.

Note that the top actor names appearing in the dashboards are names of different people which just coincide.

Afterwards, we tried to add some filters. In particular, we tried the following combinations:
* We filtered movies that were produced before 1985
* We filtered the actors height to 1.70 cm.

The corresponding dashboards can be found in the Lab7 folder. The names of the files clearly indicate the filters that were applied.

**Q64**: For this task, we decided to get the work with the heights of the actors which we already extracted in exercise 2. 
The question we want to answer is: Which are the most common weights among the actors of all the scraped movies?

The following image shows the resulting plot:
<img width="774" alt="image" src="https://github.com/chuxgs/scrapy-lab/assets/128915750/fde10522-a39c-4778-ab7c-06834fc96ad5">

Apparently the most common weight is 1.73cm. 

It is worth mentioning that we wanted to compute average weights per movie role but we saved the heights as strings instead of floats and that 
for that reason we decided to check the most common heights.

**Q65**: We have worked on this session for 15h approximately. As explained in detail in the previous sections, 
the main difficulties experienced were with the Elasticsearch connection and the scraping of multiple movies. 

